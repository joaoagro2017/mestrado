{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Treinamento e Avalia√ß√£o do Modelo com K-Fold Cross-Validation\n",
    "\n",
    "## üìö Descri√ß√£o\n",
    "Este script realiza o treinamento e avalia√ß√£o de um modelo de classifica√ß√£o com embeddings de imagens utilizando K-Fold Cross-Validation. Durante cada fold, o modelo √© treinado e validado, sendo salvos os hist√≥ricos de treinamento, m√©tricas e visualiza√ß√µes, al√©m de um relat√≥rio detalhado de desempenho.\n",
    "\n",
    "O pipeline de treinamento inclui:\n",
    "- **Carregamento dos dados:** Embeddings extra√≠dos e r√≥tulos das classes.\n",
    "- **K-Fold Cross-Validation:** Divis√£o dos dados em 10 folds.\n",
    "- **Treinamento:** Ajuste dos pesos do modelo durante 100 √©pocas por fold.\n",
    "- **Visualiza√ß√µes:** Gr√°ficos de hist√≥rico de treinamento, matriz de confus√£o e m√©tricas por fold.\n",
    "- **Exporta√ß√£o de Resultados:** Salva gr√°ficos e relat√≥rios em arquivos, gerando um ZIP no final.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Configura√ß√£o do Otimizador\n",
    "O script permite a modifica√ß√£o do otimizador do modelo. O trecho de c√≥digo respons√°vel pela configura√ß√£o do otimizador √© o seguinte:\n",
    "otimizadores como ADAM, ADAMW, s√£o nativos dessa biblioteca do pytorch. \n",
    "\n",
    "```python\n",
    "optimizer = Adam(learning_rate=0.01)  # <=== Altere o otimizador aqui\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar embeddings e r√≥tulos. (aten√ß√£o ler o dataframe do embeddings e instanciar em embeddings_df)\n",
    "X = np.array(embeddings_df['embedding'].tolist())\n",
    "y = np.array(embeddings_df['Classe'].tolist())\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classe para o otimizador PSO\n",
    "\n",
    "class PSO_Optimizer:\n",
    "    def __init__(self, model, X_train, y_train, X_val, y_val,\n",
    "                 n_particles=15, \n",
    "                 iterations=30,\n",
    "                 inertia=0.7,\n",
    "                 cognitive=1.4, \n",
    "                 social=1.4):\n",
    "        \"\"\"\n",
    "        Construtor do otimizador PSO\n",
    "        \n",
    "        Par√¢metros:\n",
    "        model -- Modelo Keras n√£o compilado\n",
    "        X_train -- Dados de treinamento\n",
    "        y_train -- Labels de treinamento\n",
    "        X_val -- Dados de valida√ß√£o\n",
    "        y_val -- Labels de valida√ß√£o\n",
    "        n_particles -- N√∫mero de part√≠culas no enxame (default: 15)\n",
    "        iterations -- N√∫mero de itera√ß√µes (default: 30)\n",
    "        inertia -- Peso de in√©rcia (default: 0.7)\n",
    "        cognitive -- Peso cognitivo (default: 1.4)\n",
    "        social -- Peso social (default: 1.4)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        \n",
    "        # Configura√ß√µes do PSO\n",
    "        self.n_particles = n_particles\n",
    "        self.iterations = iterations\n",
    "        self.inertia = inertia\n",
    "        self.cognitive = cognitive\n",
    "        self.social = social\n",
    "        \n",
    "        # Estado interno\n",
    "        self.particles = []\n",
    "        self.velocities = []\n",
    "        self.personal_best = []\n",
    "        self.personal_best_scores = []\n",
    "        self.global_best = None\n",
    "        self.global_best_score = float('inf')\n",
    "        \n",
    "        # Inicializa√ß√£o\n",
    "        self.original_weights = model.get_weights()\n",
    "        self._initialize_particles()\n",
    "\n",
    "    def _initialize_particles(self):\n",
    "        \"\"\"Inicializa as part√≠culas com varia√ß√µes nos pesos iniciais\"\"\"\n",
    "        for _ in range(self.n_particles):\n",
    "            particle = [w + np.random.normal(scale=0.1, size=w.shape) \n",
    "                       for w in self.original_weights]\n",
    "            self.particles.append(particle)\n",
    "            self.velocities.append([np.zeros_like(w) for w in self.original_weights])\n",
    "            self.personal_best.append(particle.copy())\n",
    "            self.personal_best_scores.append(float('inf'))\n",
    "\n",
    "    def _evaluate(self, weights):\n",
    "        \"\"\"Avalia um conjunto de pesos na valida√ß√£o\"\"\"\n",
    "        self.model.set_weights(weights)\n",
    "        loss, _ = self.model.evaluate(self.X_val, self.y_val, verbose=0)\n",
    "        return loss\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"Executa o processo de otimiza√ß√£o PSO\"\"\"\n",
    "        for iter in range(self.iterations):\n",
    "            # Avalia√ß√£o das part√≠culas\n",
    "            for i in range(self.n_particles):\n",
    "                current_score = self._evaluate(self.particles[i])\n",
    "                \n",
    "                # Atualiza melhor pessoal\n",
    "                if current_score < self.personal_best_scores[i]:\n",
    "                    self.personal_best_scores[i] = current_score\n",
    "                    self.personal_best[i] = self.particles[i].copy()\n",
    "                \n",
    "                # Atualiza melhor global\n",
    "                if current_score < self.global_best_score:\n",
    "                    self.global_best_score = current_score\n",
    "                    self.global_best = self.particles[i].copy()\n",
    "\n",
    "            # Atualiza√ß√£o das velocidades e posi√ß√µes\n",
    "            for i in range(self.n_particles):\n",
    "                for w in range(len(self.velocities[i])):\n",
    "                    r1, r2 = np.random.random(), np.random.random()\n",
    "                    \n",
    "                    cognitive_component = self.cognitive * r1 * (\n",
    "                        self.personal_best[i][w] - self.particles[i][w])\n",
    "                    \n",
    "                    social_component = self.social * r2 * (\n",
    "                        self.global_best[w] - self.particles[i][w])\n",
    "                    \n",
    "                    self.velocities[i][w] = (\n",
    "                        self.inertia * self.velocities[i][w] +\n",
    "                        cognitive_component +\n",
    "                        social_component\n",
    "                    )\n",
    "                    \n",
    "                    self.particles[i][w] += self.velocities[i][w]\n",
    "\n",
    "            print(f\"Itera√ß√£o {iter+1}/{self.iterations} | Melhor Loss: {self.global_best_score:.4f}\")\n",
    "\n",
    "        # Aplica os melhores pesos encontrados\n",
    "        self.model.set_weights(self.global_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatOptimizer:\n",
    "    def __init__(self, model, X_train, y_train, X_val, y_val,\n",
    "                 population_size=15, \n",
    "                 num_iterations=50,\n",
    "                 freq_min=0, \n",
    "                 freq_max=2,\n",
    "                 loudness=0.5,\n",
    "                 pulse_rate=0.5,\n",
    "                 alpha=0.9,\n",
    "                 gamma=0.9):\n",
    "        \"\"\"\n",
    "        Construtor do otimizador Bat Algorithm\n",
    "        \n",
    "        Par√¢metros:\n",
    "        model -- Modelo Keras n√£o compilado\n",
    "        X_train -- Dados de treinamento\n",
    "        y_train -- Labels de treinamento\n",
    "        X_val -- Dados de valida√ß√£o\n",
    "        y_val -- Labels de valida√ß√£o\n",
    "        population_size -- Tamanho da popula√ß√£o de morcegos (padr√£o: 15)\n",
    "        num_iterations -- N√∫mero de itera√ß√µes (padr√£o: 50)\n",
    "        freq_min -- Frequ√™ncia m√≠nima de pulso (padr√£o: 0)\n",
    "        freq_max -- Frequ√™ncia m√°xima de pulso (padr√£o: 2)\n",
    "        loudness -- Sonoridade inicial (padr√£o: 0.5)\n",
    "        pulse_rate -- Taxa inicial de pulsos (padr√£o: 0.5)\n",
    "        alpha -- Fator de decaimento da sonoridade (padr√£o: 0.9)\n",
    "        gamma -- Fator de aumento da taxa de pulsos (padr√£o: 0.9)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        \n",
    "        # Par√¢metros do algoritmo\n",
    "        self.pop_size = population_size\n",
    "        self.max_iter = num_iterations\n",
    "        self.freq_min = freq_min\n",
    "        self.freq_max = freq_max\n",
    "        self.A = loudness\n",
    "        self.r = pulse_rate\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # Estado interno\n",
    "        self.bats = []\n",
    "        self.velocities = []\n",
    "        self.frequencies = []\n",
    "        self.loudness = []\n",
    "        self.pulse_rates = []\n",
    "        self.best_solution = None\n",
    "        self.best_score = float('inf')\n",
    "        \n",
    "        # Inicializa√ß√£o\n",
    "        self.original_weights = model.get_weights()\n",
    "        self._initialize_bats()\n",
    "\n",
    "    def _initialize_bats(self):\n",
    "        \"\"\"Inicializa a popula√ß√£o de morcegos com pesos perturbados\"\"\"\n",
    "        for _ in range(self.pop_size):\n",
    "            # Cria morcego com pequenas perturba√ß√µes nos pesos originais\n",
    "            bat = [w + np.random.normal(scale=0.1, size=w.shape) \n",
    "                  for w in self.original_weights]\n",
    "            \n",
    "            self.bats.append(bat)\n",
    "            self.velocities.append([np.zeros_like(w) for w in self.original_weights])\n",
    "            self.frequencies.append(0)\n",
    "            self.loudness.append(self.A)\n",
    "            self.pulse_rates.append(self.r)\n",
    "\n",
    "    def _evaluate(self, weights):\n",
    "        \"\"\"Avalia uma solu√ß√£o usando a perda de valida√ß√£o\"\"\"\n",
    "        self.model.set_weights(weights)\n",
    "        loss, _ = self.model.evaluate(self.X_val, self.y_val, verbose=0)\n",
    "        return loss\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"Executa o processo de otimiza√ß√£o\"\"\"\n",
    "        for iteration in range(self.max_iter):\n",
    "            # Atualiza par√¢metros din√¢micos\n",
    "            avg_A = np.mean(self.loudness)\n",
    "            self.A *= self.alpha\n",
    "            self.r *= (1 - np.exp(-self.gamma * iteration))\n",
    "            \n",
    "            for i in range(self.pop_size):\n",
    "                # Gera nova solu√ß√£o\n",
    "                self.frequencies[i] = self.freq_min + (self.freq_max - self.freq_min) * np.random.random()\n",
    "                \n",
    "                # Atualiza velocidades\n",
    "                new_velocity = []\n",
    "                for v, w, best_w in zip(self.velocities[i], \n",
    "                                      self.bats[i], \n",
    "                                      self.best_solution or self.original_weights):\n",
    "                    new_v = v + (w - best_w) * self.frequencies[i]\n",
    "                    new_velocity.append(new_v)\n",
    "                self.velocities[i] = new_velocity\n",
    "                \n",
    "                # Gera solu√ß√£o candidata\n",
    "                candidate = [w + v for w, v in zip(self.bats[i], self.velocities[i])]\n",
    "                \n",
    "                # Busca local com voo aleat√≥rio\n",
    "                if random.random() > self.pulse_rates[i]:\n",
    "                    candidate = [w + np.random.normal(scale=avg_A) * random.choice([-1, 1])\n",
    "                                for w in candidate]\n",
    "                \n",
    "                # Avalia nova solu√ß√£o\n",
    "                candidate_score = self._evaluate(candidate)\n",
    "                \n",
    "                # Atualiza a solu√ß√£o se for melhor\n",
    "                if candidate_score < self._evaluate(self.bats[i]) and random.random() < self.loudness[i]:\n",
    "                    self.bats[i] = candidate\n",
    "                    \n",
    "                    # Atualiza a melhor solu√ß√£o global\n",
    "                    if candidate_score < self.best_score:\n",
    "                        self.best_score = candidate_score\n",
    "                        self.best_solution = candidate.copy()\n",
    "                        \n",
    "                # Atualiza par√¢metros do morcego\n",
    "                self.loudness[i] *= self.alpha\n",
    "                self.pulse_rates[i] *= (1 - np.exp(-self.gamma * iteration))\n",
    "\n",
    "            print(f\"Itera√ß√£o {iteration+1}/{self.max_iter} | Melhor Loss: {self.best_score:.4f}\")\n",
    "\n",
    "        # Define os melhores pesos no modelo\n",
    "        if self.best_solution is not None:\n",
    "            self.model.set_weights(self.best_solution)\n",
    "        else:\n",
    "            self.model.set_weights(self.original_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_prepare_data(csv_file):\n",
    "    \"\"\"\n",
    "    Carrega e prepara os dados do CSV com embeddings\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Converte as strings de embeddings para arrays numpy\n",
    "    embeddings = df['embedding'].apply(lambda x: np.fromstring(\n",
    "        x.strip('[]'), sep=' ')).values\n",
    "    embeddings = np.stack(embeddings)\n",
    "\n",
    "    # Codifica as classes\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(df['Classe'])\n",
    "\n",
    "    return embeddings, labels, le.classes_\n",
    "\n",
    "def create_model(input_dim, num_classes):\n",
    "    \"\"\"\n",
    "    Cria o modelo de classifica√ß√£o\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(input_dim,), kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer = PSO_Optimizer( #mudar o otimizador por aqui. ex. otimizador(parametros=valor)\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    n_particles=15,\n",
    "    iterations=30,\n",
    "    inertia=0.7,\n",
    "    cognitive=1.4,\n",
    "    social=1.4\n",
    "                  )\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def plot_fold_history(histories, output_dir):\n",
    "    \"\"\"\n",
    "    Plota o hist√≥rico de treinamento para todos os folds\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold, history in enumerate(histories):\n",
    "        plt.plot(history.history['accuracy'], label=f'Treino Fold {fold+1}')\n",
    "        plt.plot(history.history['val_accuracy'], label=f'Val Fold {fold+1}', linestyle='--')\n",
    "    plt.title('Acur√°cia do Modelo por Fold')\n",
    "    plt.xlabel('√âpoca')\n",
    "    plt.ylabel('Acur√°cia')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold, history in enumerate(histories):\n",
    "        plt.plot(history.history['loss'], label=f'Treino Fold {fold+1}')\n",
    "        plt.plot(history.history['val_loss'], label=f'Val Fold {fold+1}', linestyle='--')\n",
    "    plt.title('Perda do Modelo por Fold')\n",
    "    plt.xlabel('√âpoca')\n",
    "    plt.ylabel('Perda')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'training_history.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_fold_metrics(fold_scores, output_dir):\n",
    "    \"\"\"\n",
    "    Plota as m√©tricas finais de cada fold em um gr√°fico de barras\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    folds = range(1, len(fold_scores) + 1)\n",
    "    plt.bar(folds, fold_scores)\n",
    "    plt.axhline(y=np.mean(fold_scores), color='r', linestyle='--', label='M√©dia')\n",
    "    \n",
    "    plt.title('Acur√°cia por Fold')\n",
    "    plt.xlabel('N√∫mero do Fold')\n",
    "    plt.ylabel('Acur√°cia')\n",
    "    plt.ylim([0, 1])\n",
    "    \n",
    "    for i, v in enumerate(fold_scores):\n",
    "        plt.text(i + 1, v + 0.01, f'{v:.4f}', ha='center')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, 'fold_metrics.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, output_dir):\n",
    "    \"\"\"\n",
    "    Plota e salva a matriz de confus√£o\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Matriz de Confus√£o')\n",
    "    plt.xlabel('Predito')\n",
    "    plt.ylabel('Real')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'))\n",
    "    plt.close()\n",
    "\n",
    "def save_results(fold_scores, classification_rep, fold_times, total_time, output_dir):\n",
    "    \"\"\"\n",
    "    Salva os resultados em arquivos de texto\n",
    "    \"\"\"\n",
    "    # Salva as acur√°cias por fold e tempos de treinamento\n",
    "    with open(os.path.join(output_dir, 'fold_accuracies.txt'), 'w') as f:\n",
    "        f.write(\"Resultados por Fold:\\n\")\n",
    "        for i, (score, time_taken) in enumerate(zip(fold_scores, fold_times)):\n",
    "            f.write(f\"Fold {i+1}:\\n\")\n",
    "            f.write(f\"  Acur√°cia: {score:.4f}\\n\")\n",
    "            f.write(f\"  Tempo de treinamento: {time_taken:.2f} segundos ({time_taken/60:.2f} minutos)\\n\")\n",
    "        \n",
    "        f.write(f\"\\nM√©dia de Acur√°cia: {np.mean(fold_scores):.4f}\")\n",
    "        f.write(f\"\\nDesvio Padr√£o de Acur√°cia: {np.std(fold_scores):.4f}\")\n",
    "        f.write(f\"\\n\\nTempo m√©dio por fold: {np.mean(fold_times):.2f} segundos ({np.mean(fold_times)/60:.2f} minutos)\")\n",
    "        f.write(f\"\\nTempo total de treinamento: {total_time:.2f} segundos ({total_time/60:.2f} minutos)\")\n",
    "\n",
    "    # Salva o classification report\n",
    "    with open(os.path.join(output_dir, 'classification_report.txt'), 'w') as f:\n",
    "        f.write(classification_rep)\n",
    "\n",
    "def create_zip_archive(output_dir, zip_filename):\n",
    "    \"\"\"\n",
    "    Cria um arquivo zip com todos os resultados\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "        for root, dirs, files in os.walk(output_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, output_dir)\n",
    "                zipf.write(file_path, arcname)\n",
    "\n",
    "def main():\n",
    "    # Par√¢metros\n",
    "    csv_file = './seu_arquivo_balanceado.csv'\n",
    "    k_folds = 10\n",
    "    epochs = 100\n",
    "    batch_size = 32\n",
    "\n",
    "    # Cria diret√≥rio para os resultados\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = f'resultados_kfold_{timestamp}'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(\"Carregando dados...\")\n",
    "    embeddings, labels, classes = load_and_prepare_data(csv_file)\n",
    "\n",
    "    # Inicializa o K-Fold\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Armazena m√©tricas e hist√≥ricos\n",
    "    fold_histories = []\n",
    "    fold_scores = []\n",
    "    fold_times = []  # Lista para armazenar o tempo de cada fold\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    # Marca o in√≠cio do treinamento total\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    # Loop atrav√©s dos folds\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(embeddings)):\n",
    "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        X_train, X_val = embeddings[train_idx], embeddings[val_idx]\n",
    "        y_train, y_val = labels[train_idx], labels[val_idx]\n",
    "\n",
    "        print(f\"Treino: {X_train.shape}, Valida√ß√£o: {X_val.shape}\")\n",
    "\n",
    "        model = create_model(embeddings.shape[1], len(classes))\n",
    "        \n",
    "        # Marca o in√≠cio do treinamento do fold\n",
    "        fold_start_time = time.time()\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Calcula o tempo do fold\n",
    "        fold_time = time.time() - fold_start_time\n",
    "        fold_times.append(fold_time)\n",
    "\n",
    "        # Avalia√ß√£o e predi√ß√µes\n",
    "        scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "        predictions = model.predict(X_val)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        print(f\"\\nFold {fold + 1} - Perda: {scores[0]:.4f}, Acur√°cia: {scores[1]:.4f}\")\n",
    "        print(f\"Tempo de treinamento do fold: {fold_time:.2f} segundos ({fold_time/60:.2f} minutos)\")\n",
    "\n",
    "        # Armazena resultados\n",
    "        fold_histories.append(history)\n",
    "        fold_scores.append(scores[1])\n",
    "        all_predictions.extend(predicted_classes)\n",
    "        all_true_labels.extend(y_val)\n",
    "\n",
    "    # Calcula o tempo total de treinamento\n",
    "    total_time = time.time() - total_start_time\n",
    "\n",
    "    # Gera e salva resultados finais\n",
    "    print(\"\\nGerando relat√≥rios e visualiza√ß√µes...\")\n",
    "    \n",
    "    # Classification Report\n",
    "    report = classification_report(all_true_labels, all_predictions, \n",
    "                                 target_names=classes, digits=4)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Gera todas as visualiza√ß√µes e salva resultados\n",
    "    plot_fold_history(fold_histories, output_dir)\n",
    "    plot_fold_metrics(fold_scores, output_dir)\n",
    "    plot_confusion_matrix(all_true_labels, all_predictions, classes, output_dir)\n",
    "    save_results(fold_scores, report, fold_times, total_time, output_dir)\n",
    "\n",
    "    # Cria arquivo zip com os resultados\n",
    "    zip_filename = f'{output_dir}.zip'\n",
    "    create_zip_archive(output_dir, zip_filename)\n",
    "\n",
    "    print(f\"\\nProcesso completo. Resultados e arquivos salvos em: {zip_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

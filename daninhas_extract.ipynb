{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa de Pr√©-processamento: Extra√ß√£o de Embeddings de Imagens de Daninhas\n",
    "\n",
    "## üìö Descri√ß√£o\n",
    "Esta etapa do pipeline de processamento √© respons√°vel por receber imagens de plantas daninhas, realizar o pr√©-processamento necess√°rio e extrair **embeddings** utilizando um modelo pr√©-treinado. Os embeddings servir√£o como vetores de caracter√≠sticas que ser√£o utilizados nas etapas posteriores de classifica√ß√£o e an√°lise.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Etapas do Pr√©-processamento\n",
    "1. **Carregamento das Imagens:**  \n",
    "   - As imagens s√£o carregadas a partir de um diret√≥rio especificado.\n",
    "   - Caso as imagens n√£o estejam em um espa√ßo de cores RGB elas ser√£o convertidas\n",
    "   - Cada imagem √© redimensionada para o tamanho esperado pelo modelo pr√©-treinado (por exemplo, 299x299 pixels para \"imagenet\").\n",
    "   \n",
    "2. **Normaliza√ß√£o das Imagens:**  \n",
    "   - Os valores dos pixels s√£o escalados para o intervalo [0, 1] ou normalizados conforme os requisitos do modelo.\n",
    "\n",
    "3. **Data Augmentation (Opcional):**  \n",
    "   - T√©cnicas como rota√ß√£o, flip horizontal/vertical e ajuste de brilho s√£o aplicadas para aumentar a variabilidade do conjunto de dados.\n",
    "\n",
    "4. **Extra√ß√£o de Embeddings:**  \n",
    "   - Um modelo pr√©-treinado (imagenet) √© carregado sem a camada de classifica√ß√£o.\n",
    "   - As imagens s√£o passadas pelo modelo, e os embeddings (vetores de caracter√≠sticas) s√£o extra√≠dos da pen√∫ltima camada.\n",
    "\n",
    "5. **Tratamento dos Embeddings e balanceamento:**  \n",
    "   - O arquivo vetorial √© salvo em uma planilha com as caracteristicas e sua respectiva classe.\n",
    "   - caso necess√°rio para otimizar o treinamento pode ser feito um balanceamento por oversampling aumentando as amostras de menor n√∫mero.\n",
    "   \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm().pandas()\n",
    "from tensorflow.keras.optimizers import *\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras_facenet import FaceNet\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caso suas imagens n√£o esteja em rgb\n",
    "def convert_images_to_rgb(root_folder):\n",
    "    \"\"\"\n",
    "    Converte todas as imagens em um diret√≥rio e seus subdiret√≥rios para o formato RGB.\n",
    "    \n",
    "    Args:\n",
    "        root_folder (str): Caminho para a pasta raiz contendo os subdiret√≥rios com as imagens.\n",
    "    \"\"\"\n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                with Image.open(file_path) as img:\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "                        img.save(file_path)\n",
    "                        print(f'Convertido para RGB: {file_path}')\n",
    "                    else:\n",
    "                        print(f'J√° est√° em RGB: {file_path}')\n",
    "            except Exception as e:\n",
    "                print(f'Erro ao processar {file_path}: {e}')\n",
    "\n",
    "# Caminho para a pasta raiz\n",
    "root_folder = \"./caminho das imagens aqui\"\n",
    "convert_images_to_rgb(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diret√≥rio das imagens\n",
    "dataset_path = 'caminho das imagens aqui'\n",
    "\n",
    "# Fun√ß√£o para carregar imagens e r√≥tulos\n",
    "def load_dataset(dataset_path, target_size=(299, 299)):\n",
    "    data = []\n",
    "    labels = []\n",
    "    classes = os.listdir(dataset_path)\n",
    "    \n",
    "    for class_label in classes:\n",
    "        class_path = os.path.join(dataset_path, class_label)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                img = Image.open(img_path).resize(target_size)\n",
    "                img = np.array(img)\n",
    "                data.append(img)\n",
    "                labels.append(class_label)\n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = load_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o modelo base\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializar o gerador de dados com augmenta√ß√£o\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Pr√©-processar as imagens\n",
    "X_preprocessed = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gerar embeddings para imagens aumentadas\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(X_preprocessed)):\n",
    "    img = X_preprocessed[i]\n",
    "    label = y[i]\n",
    "    \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    for batch in datagen.flow(img, batch_size=1):\n",
    "        augmented_img = batch[0]\n",
    "        augmented_img = np.expand_dims(augmented_img, axis=0)\n",
    "        embedding = model.predict(augmented_img)\n",
    "        \n",
    "        embeddings.append(embedding[0])\n",
    "        labels.append(label)\n",
    "        \n",
    "        # Gerar 5 aumentos por imagem\n",
    "        if len(labels) >= (i+1) * 5:\n",
    "            break\n",
    "\n",
    "# Converter para DataFrame\n",
    "embeddings_df = pd.DataFrame({\n",
    "    'Classe': labels,\n",
    "    'embedding': list(embeddings)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o DataFrame em um CSV\n",
    "embeddings_df.to_csv('embeddings_with_augmentation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('embeddings_with_augmentation.npz', embeddings=embeddings, labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Carregar os dados\n",
    "file_path = './embeddings_with_augmentation.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Corrigir formata√ß√£o e converter embeddings para vetores NumPy\n",
    "def fix_and_convert_embedding(embedding_str):\n",
    "    # Remove leading/trailing whitespace and brackets\n",
    "    embedding_str = embedding_str.strip('[]')\n",
    "    \n",
    "    # Convert the string to a NumPy array\n",
    "    values = np.fromstring(embedding_str, sep=' ')\n",
    "    \n",
    "    return values\n",
    "\n",
    "def preprocess_embeddings(data):\n",
    "    data['embedding'] = data['embedding'].apply(fix_and_convert_embedding)\n",
    "    return data\n",
    "\n",
    "# Aplicar SMOTE para balancear classes\n",
    "def apply_smote(data, target_column, embedding_column):\n",
    "    # Separar as features (X) e o alvo (y)\n",
    "    X = np.stack(data[embedding_column].values)\n",
    "    y = data[target_column]\n",
    "    \n",
    "    # Aplicar SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    \n",
    "    # Retornar os dados balanceados como um novo DataFrame\n",
    "    balanced_data = pd.DataFrame({\n",
    "        target_column: y_resampled,\n",
    "        embedding_column: list(X_resampled)\n",
    "    })\n",
    "    return balanced_data\n",
    "\n",
    "# Processar os dados e aplicar SMOTE\n",
    "data = preprocess_embeddings(data)\n",
    "balanced_data = apply_smote(data, target_column=\"Classe\", embedding_column=\"embedding\")\n",
    "\n",
    "# Salvar o resultado em um novo arquivo CSV\n",
    "output_path = 'balanced_embeddings.csv'\n",
    "balanced_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Arquivo balanceado salvo em: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

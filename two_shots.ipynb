{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import time\n",
    "import copy\n",
    "\n",
    "classes = ['Pastos', 'planta_daninha', 'planta_toxicas']\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, csv_file, num_classes=3):\n",
    "        self.data = pd.read_csv(csv_file, header=0)\n",
    "        self.num_classes = num_classes\n",
    "        self.class_to_idx = {classes[i]: i for i in range(num_classes)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label_str, embedding_str = self.data.iloc[idx]\n",
    "        label = self.class_to_idx[label_str]\n",
    "        embedding = np.fromstring(embedding_str.strip('[]'), sep=' ')\n",
    "        embedding = torch.tensor(embedding, dtype=torch.float32)\n",
    "        return embedding, label\n",
    "\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(EmbeddingClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_fold_history(histories, output_dir):\n",
    "    \"\"\"\n",
    "    Plota o histórico de treinamento para todos os folds\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold, history in enumerate(histories):\n",
    "        plt.plot(history['train_acc'], label=f'Treino Fold {fold+1}')\n",
    "        plt.plot(history['val_acc'], label=f'Val Fold {fold+1}', linestyle='--')\n",
    "    plt.title('Acurácia do Modelo por Fold')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold, history in enumerate(histories):\n",
    "        plt.plot(history['train_loss'], label=f'Treino Fold {fold+1}')\n",
    "        plt.plot(history['val_loss'], label=f'Val Fold {fold+1}', linestyle='--')\n",
    "    plt.title('Perda do Modelo por Fold')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Perda')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'training_history.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_fold_metrics(fold_scores, output_dir):\n",
    "    \"\"\"\n",
    "    Plota as métricas finais de cada fold em um gráfico de barras\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    folds = range(1, len(fold_scores) + 1)\n",
    "    plt.bar(folds, fold_scores)\n",
    "    plt.axhline(y=np.mean(fold_scores), color='r', linestyle='--', label='Média')\n",
    "    \n",
    "    plt.title('Acurácia por Fold')\n",
    "    plt.xlabel('Número do Fold')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.ylim([0, 1])\n",
    "    \n",
    "    for i, v in enumerate(fold_scores):\n",
    "        plt.text(i + 1, v + 0.01, f'{v:.4f}', ha='center')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, 'fold_metrics.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, output_dir):\n",
    "    \"\"\"\n",
    "    Plota e salva a matriz de confusão\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Matriz de Confusão')\n",
    "    plt.xlabel('Predito')\n",
    "    plt.ylabel('Real')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'))\n",
    "    plt.close()\n",
    "\n",
    "def save_results(fold_scores, classification_rep, fold_times, total_time, output_dir):\n",
    "    \"\"\"\n",
    "    Salva os resultados em arquivos de texto\n",
    "    \"\"\"\n",
    "    with open(os.path.join(output_dir, 'fold_accuracies.txt'), 'w') as f:\n",
    "        f.write(\"Resultados por Fold:\\n\")\n",
    "        for i, (score, time_taken) in enumerate(zip(fold_scores, fold_times)):\n",
    "            f.write(f\"Fold {i+1}:\\n\")\n",
    "            f.write(f\"  Acurácia: {score:.4f}\\n\")\n",
    "            f.write(f\"  Tempo de treinamento: {time_taken:.2f} segundos ({time_taken/60:.2f} minutos)\\n\")\n",
    "        \n",
    "        f.write(f\"\\nMédia de Acurácia: {np.mean(fold_scores):.4f}\")\n",
    "        f.write(f\"\\nDesvio Padrão de Acurácia: {np.std(fold_scores):.4f}\")\n",
    "        f.write(f\"\\n\\nTempo médio por fold: {np.mean(fold_times):.2f} segundos ({np.mean(fold_times)/60:.2f} minutos)\")\n",
    "        f.write(f\"\\nTempo total de treinamento: {total_time:.2f} segundos ({total_time/60:.2f} minutos)\")\n",
    "\n",
    "    with open(os.path.join(output_dir, 'classification_report.txt'), 'w') as f:\n",
    "        f.write(classification_rep)\n",
    "\n",
    "def create_zip_archive(output_dir, zip_filename):\n",
    "    \"\"\"\n",
    "    Cria um arquivo zip com todos os resultados\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "        for root, dirs, files in os.walk(output_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, output_dir)\n",
    "                zipf.write(file_path, arcname)\n",
    "\n",
    "def train_evaluate_fold(model, train_loader, val_loader, criterion, optimizer, device, num_epochs):\n",
    "    \"\"\"\n",
    "    Treina e avalia o modelo para um fold específico\n",
    "    \"\"\"\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Record history\n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['train_acc'].append(train_correct / train_total)\n",
    "        history['val_loss'].append(val_loss / len(val_loader))\n",
    "        history['val_acc'].append(val_correct / val_total)\n",
    "        \n",
    "    return history, val_correct / val_total\n",
    "\n",
    "def main():\n",
    "    # Configurações\n",
    "    csv_file = '../../embeddings_with_augmentation.csv'\n",
    "    k_folds = 10\n",
    "    num_epochs = 100\n",
    "    batch_size = 32\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Criar diretório para resultados\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = f'resultados_kfold_{timestamp}'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Carregar dataset\n",
    "    print(\"Carregando dados...\")\n",
    "    dataset = EmbeddingDataset(csv_file)\n",
    "    input_dim = dataset[0][0].shape[0]\n",
    "    \n",
    "    # Inicializar K-Fold\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Métricas e históricos\n",
    "    fold_histories = []\n",
    "    fold_scores = []\n",
    "    fold_times = []\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    # Marca o início do treinamento total\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    # Loop através dos folds\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "        # Preparar dataloaders\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        val_sampler = SubsetRandomSampler(val_idx)\n",
    "        \n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "        val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "        \n",
    "        # Inicializar modelo, critério e otimizador\n",
    "        model = EmbeddingClassifier(input_dim, len(classes)).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Marca o início do treinamento do fold\n",
    "        fold_start_time = time.time()\n",
    "        \n",
    "        # Treinar e avaliar o fold\n",
    "        history, fold_accuracy = train_evaluate_fold(\n",
    "            model, train_loader, val_loader, criterion, optimizer, device, num_epochs\n",
    "        )\n",
    "        \n",
    "        # Calcular o tempo do fold\n",
    "        fold_time = time.time() - fold_start_time\n",
    "        fold_times.append(fold_time)\n",
    "        \n",
    "        # Coletar predições para a matriz de confusão\n",
    "        model.eval()\n",
    "        fold_preds = []\n",
    "        fold_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                fold_preds.extend(predicted.cpu().numpy())\n",
    "                fold_labels.extend(labels.numpy())\n",
    "        \n",
    "        all_predictions.extend(fold_preds)\n",
    "        all_true_labels.extend(fold_labels)\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        fold_histories.append(history)\n",
    "        fold_scores.append(fold_accuracy)\n",
    "        \n",
    "        print(f\"Fold {fold + 1} - Acurácia: {fold_accuracy:.4f}\")\n",
    "        print(f\"Tempo de treinamento do fold: {fold_time:.2f} segundos ({fold_time/60:.2f} minutos)\")\n",
    "    \n",
    "    # Calcular o tempo total de treinamento\n",
    "    total_time = time.time() - total_start_time\n",
    "    \n",
    "    # Gerar relatório de classificação\n",
    "    report = classification_report(all_true_labels, all_predictions, \n",
    "                                 target_names=classes, digits=4)\n",
    "    \n",
    "    # Gerar visualizações e salvar resultados\n",
    "    print(\"\\nGerando relatórios e visualizações...\")\n",
    "    plot_fold_history(fold_histories, output_dir)\n",
    "    plot_fold_metrics(fold_scores, output_dir)\n",
    "    plot_confusion_matrix(all_true_labels, all_predictions, output_dir)\n",
    "    save_results(fold_scores, report, fold_times, total_time, output_dir)\n",
    "    \n",
    "    # Criar arquivo zip\n",
    "    zip_filename = f'resultados_kfold_{timestamp}.zip'\n",
    "    create_zip_archive(output_dir, zip_filename)\n",
    "    \n",
    "    print(f\"\\nResultados da Validação Cruzada:\")\n",
    "    print(f\"Acurácia média: {np.mean(fold_scores):.4f} (+/- {np.std(fold_scores):.4f})\")\n",
    "    print(f\"Tempo médio por fold: {np.mean(fold_times):.2f} segundos ({np.mean(fold_times)/60:.2f} minutos)\")\n",
    "    print(f\"Tempo total de treinamento: {total_time:.2f} segundos ({total_time/60:.2f} minutos)\")\n",
    "    print(f\"\\nTodos os resultados foram salvos em '{zip_filename}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

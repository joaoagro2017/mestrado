{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "################### 1 SHOT #########\n",
    "# Dataset class\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, csv_file, num_classes=3):\n",
    "        self.data = pd.read_csv(csv_file, header=0)\n",
    "        self.num_classes = num_classes\n",
    "        self.classes = ['Pastos', 'planta_daninha', 'planta_toxicas']\n",
    "        self.class_to_idx = {self.classes[i]: i for i in range(num_classes)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label_str, embedding_str = self.data.iloc[idx]\n",
    "        label = self.class_to_idx[label_str]\n",
    "        embedding = np.fromstring(embedding_str.strip('[]'), sep=' ')\n",
    "        embedding = torch.tensor(embedding, dtype=torch.float32)\n",
    "        return embedding, label\n",
    "\n",
    "# Model definition\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(EmbeddingClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "def plot_fold_history(fold_histories, output_dir):\n",
    "    \"\"\"Plot training history for all folds\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold, history in enumerate(fold_histories):\n",
    "        plt.plot(history['train_loss'], label=f'Train Fold {fold+1}')\n",
    "        plt.plot(history['val_loss'], label=f'Val Fold {fold+1}', linestyle='--')\n",
    "    plt.title('Model Loss by Fold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold, history in enumerate(fold_histories):\n",
    "        plt.plot(history['train_acc'], label=f'Train Fold {fold+1}')\n",
    "        plt.plot(history['val_acc'], label=f'Val Fold {fold+1}', linestyle='--')\n",
    "    plt.title('Model Accuracy by Fold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'training_history.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_fold_metrics(fold_scores, output_dir):\n",
    "    \"\"\"Plot final metrics for each fold\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    folds = range(1, len(fold_scores) + 1)\n",
    "    plt.bar(folds, fold_scores)\n",
    "    plt.axhline(y=np.mean(fold_scores), color='r', linestyle='--', label='Mean')\n",
    "    \n",
    "    plt.title('Accuracy by Fold')\n",
    "    plt.xlabel('Fold Number')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 1])\n",
    "    \n",
    "    for i, v in enumerate(fold_scores):\n",
    "        plt.text(i + 1, v + 0.01, f'{v:.4f}', ha='center')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, 'fold_metrics.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, output_dir):\n",
    "    \"\"\"Plot and save confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'))\n",
    "    plt.close()\n",
    "\n",
    "def save_results(fold_scores, classification_rep, fold_times, total_time, output_dir):\n",
    "    \"\"\"Save results to text files\"\"\"\n",
    "    with open(os.path.join(output_dir, 'fold_accuracies.txt'), 'w') as f:\n",
    "        f.write(\"Results by Fold:\\n\")\n",
    "        for i, (score, time_taken) in enumerate(zip(fold_scores, fold_times)):\n",
    "            f.write(f\"Fold {i+1}:\\n\")\n",
    "            f.write(f\"  Accuracy: {score:.4f}\\n\")\n",
    "            f.write(f\"  Training time: {time_taken:.2f} seconds ({time_taken/60:.2f} minutes)\\n\")\n",
    "        \n",
    "        f.write(f\"\\nMean Accuracy: {np.mean(fold_scores):.4f}\")\n",
    "        f.write(f\"\\nAccuracy Standard Deviation: {np.std(fold_scores):.4f}\")\n",
    "        f.write(f\"\\n\\nAverage time per fold: {np.mean(fold_times):.2f} seconds ({np.mean(fold_times)/60:.2f} minutes)\")\n",
    "        f.write(f\"\\nTotal training time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "\n",
    "    with open(os.path.join(output_dir, 'classification_report.txt'), 'w') as f:\n",
    "        f.write(classification_rep)\n",
    "\n",
    "def create_zip_archive(output_dir, zip_filename):\n",
    "    \"\"\"Create zip archive with all results\"\"\"\n",
    "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "        for root, dirs, files in os.walk(output_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, output_dir)\n",
    "                zipf.write(file_path, arcname)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=100):\n",
    "    \"\"\"Train the model and return training history\"\"\"\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Record history\n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['train_acc'].append(train_correct / train_total)\n",
    "        history['val_loss'].append(val_loss / len(val_loader))\n",
    "        history['val_acc'].append(val_correct / val_total)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], '\n",
    "                  f'Train Loss: {train_loss/len(train_loader):.4f}, '\n",
    "                  f'Train Acc: {train_correct/train_total:.4f}, '\n",
    "                  f'Val Loss: {val_loss/len(val_loader):.4f}, '\n",
    "                  f'Val Acc: {val_correct/val_total:.4f}')\n",
    "    \n",
    "    return history\n",
    "\n",
    "def main():\n",
    "    # Parameters\n",
    "    csv_file = '../../embeddings_with_augmentation.csv'\n",
    "    k_folds = 10\n",
    "    epochs = 100\n",
    "    batch_size = 32\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Create output directory\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = f'resultados_kfold_{timestamp}'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load dataset\n",
    "    print(\"Loading data...\")\n",
    "    dataset = EmbeddingDataset(csv_file)\n",
    "    input_dim = dataset[0][0].shape[0]\n",
    "    \n",
    "    # Initialize K-Fold\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Storage for metrics\n",
    "    fold_histories = []\n",
    "    fold_scores = []\n",
    "    fold_times = []\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    # Record total training time\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    # K-Fold Cross Validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(dataset)))):\n",
    "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "        # Create data loaders for this fold\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        val_sampler = SubsetRandomSampler(val_idx)\n",
    "        \n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "        val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "        \n",
    "        # Initialize model, criterion, and optimizer\n",
    "        model = EmbeddingClassifier(input_dim=input_dim, num_classes=len(dataset.classes)).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Train the model\n",
    "        fold_start_time = time.time()\n",
    "        history = train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs)\n",
    "        fold_time = time.time() - fold_start_time\n",
    "        \n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        fold_predictions = []\n",
    "        fold_true_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                fold_predictions.extend(predicted.cpu().numpy())\n",
    "                fold_true_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Record metrics\n",
    "        fold_acc = val_correct / val_total\n",
    "        print(f\"Fold {fold + 1} - Accuracy: {fold_acc:.4f}\")\n",
    "        print(f\"Training time: {fold_time:.2f} seconds ({fold_time/60:.2f} minutes)\")\n",
    "        \n",
    "        fold_histories.append(history)\n",
    "        fold_scores.append(fold_acc)\n",
    "        fold_times.append(fold_time)\n",
    "        all_predictions.extend(fold_predictions)\n",
    "        all_true_labels.extend(fold_true_labels)\n",
    "    \n",
    "    # Calculate total training time\n",
    "    total_time = time.time() - total_start_time\n",
    "    \n",
    "    # Generate and save final results\n",
    "    print(\"\\nGenerating reports and visualizations...\")\n",
    "    \n",
    "    # Classification Report\n",
    "    report = classification_report(all_true_labels, all_predictions, \n",
    "                                 target_names=dataset.classes, digits=4)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Generate all visualizations and save results\n",
    "    plot_fold_history(fold_histories, output_dir)\n",
    "    plot_fold_metrics(fold_scores, output_dir)\n",
    "    plot_confusion_matrix(all_true_labels, all_predictions, dataset.classes, output_dir)\n",
    "    save_results(fold_scores, report, fold_times, total_time, output_dir)\n",
    "    \n",
    "    # Create zip file with all results\n",
    "    zip_filename = f'resultados_kfold_{timestamp}.zip'\n",
    "    create_zip_archive(output_dir, zip_filename)\n",
    "    \n",
    "    print(f\"\\nCross Validation Results:\")\n",
    "    print(f\"Mean accuracy: {np.mean(fold_scores):.4f} (+/- {np.std(fold_scores):.4f})\")\n",
    "    print(f\"Average time per fold: {np.mean(fold_times):.2f} seconds ({np.mean(fold_times)/60:.2f} minutes)\")\n",
    "    print(f\"Total training time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "    print(f\"\\nAll results have been saved to '{zip_filename}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

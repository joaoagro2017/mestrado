{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "################### SIX SHOT #########\n",
    "\n",
    "\n",
    "# Definir as classes esperadas\n",
    "classes = ['Pastos', 'planta_daninha', 'planta_toxicas']  \n",
    "\n",
    "# Definir um Dataset personalizado para lidar com embeddings\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, csv_file, num_classes=3):\n",
    "        self.data = pd.read_csv(csv_file, header=0)  # Lê o CSV com o cabeçalho\n",
    "        self.num_classes = num_classes\n",
    "        self.class_to_idx = {classes[i]: i for i in range(num_classes)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label_str, embedding_str = self.data.iloc[idx]\n",
    "        label = self.class_to_idx[label_str]\n",
    "        embedding = np.fromstring(embedding_str.strip('[]'), sep=' ')\n",
    "        embedding = torch.tensor(embedding, dtype=torch.float32)\n",
    "        return embedding, label\n",
    "\n",
    "# Definir o DataLoader\n",
    "csv_file = './embeddings_with_augmentation.csv'  \n",
    "dataset = EmbeddingDataset(csv_file)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Redefinir a CNN para lidar com embeddings\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(EmbeddingClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Obtenha o tamanho do embedding (input_dim) a partir de um exemplo do dataset\n",
    "input_dim = dataset[0][0].shape[0]\n",
    "\n",
    "# Instanciar o modelo\n",
    "model = EmbeddingClassifier(input_dim=input_dim, num_classes=len(classes))\n",
    "\n",
    "# Definir a função de perda e otimizador\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "meta_optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Função para calcular a acurácia\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# Inner loop para aprendizado six-shot (atualização específica da tarefa)\n",
    "def inner_loop(support_inputs, support_labels, model, loss_fn, lr=0.01):\n",
    "    temp_model = copy.deepcopy(model)\n",
    "    temp_optimizer = optim.SGD(temp_model.parameters(), lr=lr)\n",
    "    temp_optimizer.zero_grad()\n",
    "    outputs = temp_model(support_inputs)\n",
    "    loss = loss_fn(outputs, support_labels)\n",
    "    loss.backward()\n",
    "    temp_optimizer.step()\n",
    "    return temp_model\n",
    "\n",
    "# Outer loop (meta-atualização)\n",
    "def outer_loop(train_loader, model, meta_optimizer, loss_fn, train_losses, train_accuracies, num_tasks=1):\n",
    "    meta_optimizer.zero_grad()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    for task_data in train_loader:\n",
    "        inputs, labels = task_data\n",
    "        \n",
    "        # Dividir os dados em support e query sets (six-shot)\n",
    "        support_inputs, query_inputs = inputs[:len(inputs) - 2], inputs[len(inputs) - 2:]\n",
    "        support_labels, query_labels = labels[:len(labels) - 2], labels[len(labels) - 2:]\n",
    "        \n",
    "        # Inner loop\n",
    "        temp_model = inner_loop(support_inputs, support_labels, model, loss_fn)\n",
    "        \n",
    "        # Avaliar no conjunto de consultas (query set)\n",
    "        query_outputs = temp_model(query_inputs)\n",
    "        query_loss = loss_fn(query_outputs, query_labels)\n",
    "        \n",
    "        # Coletar perda e acurácia\n",
    "        epoch_loss += query_loss.item()\n",
    "        epoch_accuracy += calculate_accuracy(query_outputs, query_labels)\n",
    "        \n",
    "        # Retropropagar o meta-gradiente\n",
    "        query_loss.backward()\n",
    "    \n",
    "    meta_optimizer.step()\n",
    "    \n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    avg_train_accuracy = epoch_accuracy / len(train_loader)\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(avg_train_accuracy)\n",
    "    \n",
    "    return avg_train_loss, avg_train_accuracy\n",
    "\n",
    "# Avaliação do modelo\n",
    "def evaluate_model(test_loader, test_losses, test_accuracies):\n",
    "    model.eval()\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            outputs = model(data)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    avg_test_accuracy = correct_predictions / total_samples\n",
    "    test_losses.append(avg_test_loss)\n",
    "    test_accuracies.append(avg_test_accuracy)\n",
    "\n",
    "    return avg_test_loss, avg_test_accuracy\n",
    "\n",
    "# Função para plotar as métricas individualmente\n",
    "def plot_individual_metrics(epochs, values, label, title, ylabel):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, values, 'b-', label=label)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Função para plotar todas as métricas separadamente\n",
    "def plot_metrics_separately(train_losses, train_accuracies, test_losses, test_accuracies):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    plot_individual_metrics(epochs, train_losses, 'Perda de Treinamento', 'Perda de Treinamento', 'Perda')\n",
    "    plot_individual_metrics(epochs, test_losses, 'Perda de Teste', 'Perda de Teste', 'Perda')\n",
    "    plot_individual_metrics(epochs, train_accuracies, 'Acurácia de Treinamento', 'Acurácia de Treinamento', 'Acurácia')\n",
    "    plot_individual_metrics(epochs, test_accuracies, 'Acurácia de Teste', 'Acurácia de Teste', 'Acurácia')\n",
    "\n",
    "# Treinamento com coleta de métricas\n",
    "num_epochs = 25\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_train_loss, avg_train_accuracy = outer_loop(train_loader, model, meta_optimizer, loss_fn, train_losses, train_accuracies)\n",
    "    avg_test_loss, avg_test_accuracy = evaluate_model(test_loader, test_losses, test_accuracies)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_accuracy:.4f}, Test Loss: {avg_test_loss:.4f}, Test Acc: {avg_test_accuracy:.4f}\")\n",
    "\n",
    "# Plotar as métricas individualmente\n",
    "plot_metrics_separately(train_losses, train_accuracies, test_losses, test_accuracies)\n",
    "\n",
    "# Avaliação final do modelo\n",
    "accuracy = 100 * test_accuracies[-1]\n",
    "print(f\"Accuracy on the new task or domain: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
